{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f59f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "HPD_PATH = Path(\"/mnt/d/climate_data/hpd/data/\")\n",
    "GHCND_PATH = Path(\"/mnt/d/climate_data/ghcnd/data/\")\n",
    "DATA_DOC_PATH = Path(\"./data/dataset_docs/\")\n",
    "OE_PATH = Path(\"/mnt/d/climate_data/HPD_CONUS_OEVENTS/\")\n",
    "\n",
    "VIMD_PATH = Path(\"/mnt/d/climate_data/ERA5_CONUS_VIMD/\")\n",
    "W500_PATH = Path(\"/mnt/d/climate_data/ERA5_CONUS/\")\n",
    "\n",
    "# Path for ERA5_df\n",
    "ERA5_PATH = Path(\"/mnt/d/climate_data/ERA5_CONUS_STATIONS/\")\n",
    "ERA5_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0f17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_era5_data(start_year, end_year):\n",
    "    print(f\"Loading ERA5 data from {start_year} to {end_year}...\")\n",
    "\n",
    "    w500_files = sorted([\n",
    "        f for f in W500_PATH.glob(\"ERA5_CONUS_W500_*.grib\")\n",
    "        if start_year <= int(f.name.split(\"_\")[-1][:4]) <= end_year\n",
    "    ])\n",
    "    w500_ds = xr.concat(\n",
    "        [xr.open_dataset(f, engine=\"cfgrib\") for f in w500_files], dim=\"time\"\n",
    "    )\n",
    "\n",
    "    vimd_files = sorted([\n",
    "        f for f in VIMD_PATH.glob(\"ERA5_CONUS_VIMD_*.grib\")\n",
    "        if start_year <= int(f.name.split(\"_\")[-1][:4]) <= end_year\n",
    "    ])\n",
    "    vimd_ds = xr.concat(\n",
    "        [xr.open_dataset(f, engine=\"cfgrib\") for f in vimd_files], dim=\"time\"\n",
    "    )\n",
    "\n",
    "    print(f\"ERA5 data ({start_year}-{end_year}) loaded successfully.\")\n",
    "    return w500_ds, vimd_ds\n",
    "\n",
    "\n",
    "def extract_era5_at_station(lat, lon, utc_offset, w500_ds, vimd_ds):\n",
    "    \"\"\"\n",
    "    Notes: ERA5 short forecast data like VIMD are recorded as forecast steps (1-12 hours)\n",
    "    from two daily forecast start times (06 and 18 UTC). Since files are stored\n",
    "    monthly, the forecast steps at the boundaries (first and last day of the month)\n",
    "    may point to times outside the file's time range. This causes NaN values at\n",
    "    the start/end of each month.\n",
    "\n",
    "    Instead of globally cleaning the full dataset, which is large, these\n",
    "    NaNs are removed locally per station after selecting and flattening the relevant series\n",
    "    for memory efficiency.\n",
    "    \"\"\"\n",
    "    # W500 (direct hourly data)\n",
    "    w500_series = (\n",
    "        w500_ds.w.sel(longitude=lon, latitude=lat, method=\"nearest\")\n",
    "        .to_series()\n",
    "        .rename(\"W500\")\n",
    "    )\n",
    "    w500_series.index += utc_offset  # UTC → local time\n",
    "\n",
    "    # VIMD (short forecast)\n",
    "    valid_time = vimd_ds.time.values[:, None] + vimd_ds.step.values[None, :]\n",
    "    vimd_values = vimd_ds.vimd.sel(\n",
    "        longitude=lon, latitude=lat, method=\"nearest\"\n",
    "    ).values.ravel()\n",
    "    valid_time = valid_time.ravel()\n",
    "\n",
    "    unique_mask = ~np.isnan(vimd_values)\n",
    "    vimc_series = (\n",
    "        pd.Series(\n",
    "            vimd_values[unique_mask], index=pd.to_datetime(valid_time[unique_mask])\n",
    "        )\n",
    "        .mul(-1)  # Convert to VIMC\n",
    "        .rename(\"VIMC\")\n",
    "    )\n",
    "    vimc_series.index += utc_offset  # UTC → local time\n",
    "\n",
    "    return pd.concat([w500_series, vimc_series], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4e46b",
   "metadata": {},
   "source": [
    "# Extract data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0aa336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 604 out of 1324 stations\n"
     ]
    }
   ],
   "source": [
    "potential_stations = pd.read_csv(DATA_DOC_PATH / \"hpd_hadisd.csv\")\n",
    "#potential_stations = pd.read_csv(DATA_DOC_PATH / \"potential_pt_stations.csv\")\n",
    "\n",
    "temp_dir = ERA5_PATH / \"temp\"\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Filter out stations that already have final output files\n",
    "stations_to_process = []\n",
    "for idx, row in potential_stations.iterrows():\n",
    "    stn_id = row[\"StnID\"]\n",
    "    final_file = ERA5_PATH / f\"{stn_id}.csv\"\n",
    "    if not final_file.exists():\n",
    "        stations_to_process.append((idx, row))\n",
    "\n",
    "print(f\"Processing {len(stations_to_process)} out of {len(potential_stations)} stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4908db88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ERA5 data from 1940 to 1940...\n",
      "ERA5 data (1940-1940) loaded successfully.\n",
      "Loading ERA5 data from 1941 to 1941...\n",
      "ERA5 data (1941-1941) loaded successfully.\n",
      "Loading ERA5 data from 1942 to 1942...\n",
      "ERA5 data (1942-1942) loaded successfully.\n",
      "Loading ERA5 data from 1943 to 1943...\n",
      "ERA5 data (1943-1943) loaded successfully.\n",
      "Loading ERA5 data from 1944 to 1944...\n",
      "ERA5 data (1944-1944) loaded successfully.\n",
      "Loading ERA5 data from 1945 to 1945...\n",
      "ERA5 data (1945-1945) loaded successfully.\n",
      "Loading ERA5 data from 1946 to 1946...\n",
      "ERA5 data (1946-1946) loaded successfully.\n",
      "Loading ERA5 data from 1947 to 1947...\n",
      "ERA5 data (1947-1947) loaded successfully.\n",
      "Loading ERA5 data from 1948 to 1948...\n",
      "ERA5 data (1948-1948) loaded successfully.\n",
      "Loading ERA5 data from 1949 to 1949...\n",
      "ERA5 data (1949-1949) loaded successfully.\n",
      "Loading ERA5 data from 1950 to 1950...\n",
      "ERA5 data (1950-1950) loaded successfully.\n",
      "Loading ERA5 data from 1951 to 1951...\n",
      "ERA5 data (1951-1951) loaded successfully.\n",
      "Loading ERA5 data from 1952 to 1952...\n",
      "ERA5 data (1952-1952) loaded successfully.\n",
      "Loading ERA5 data from 1953 to 1953...\n",
      "ERA5 data (1953-1953) loaded successfully.\n",
      "Loading ERA5 data from 1954 to 1954...\n",
      "ERA5 data (1954-1954) loaded successfully.\n",
      "Loading ERA5 data from 1955 to 1955...\n",
      "ERA5 data (1955-1955) loaded successfully.\n",
      "Loading ERA5 data from 1956 to 1956...\n",
      "ERA5 data (1956-1956) loaded successfully.\n",
      "Loading ERA5 data from 1957 to 1957...\n",
      "ERA5 data (1957-1957) loaded successfully.\n",
      "Loading ERA5 data from 1958 to 1958...\n",
      "ERA5 data (1958-1958) loaded successfully.\n",
      "Loading ERA5 data from 1959 to 1959...\n",
      "ERA5 data (1959-1959) loaded successfully.\n",
      "Loading ERA5 data from 1960 to 1960...\n",
      "ERA5 data (1960-1960) loaded successfully.\n",
      "Loading ERA5 data from 1961 to 1961...\n",
      "ERA5 data (1961-1961) loaded successfully.\n",
      "Loading ERA5 data from 1962 to 1962...\n",
      "ERA5 data (1962-1962) loaded successfully.\n",
      "Loading ERA5 data from 1963 to 1963...\n",
      "ERA5 data (1963-1963) loaded successfully.\n",
      "Loading ERA5 data from 1964 to 1964...\n",
      "ERA5 data (1964-1964) loaded successfully.\n",
      "Loading ERA5 data from 1965 to 1965...\n",
      "ERA5 data (1965-1965) loaded successfully.\n",
      "Loading ERA5 data from 1966 to 1966...\n",
      "ERA5 data (1966-1966) loaded successfully.\n",
      "Loading ERA5 data from 1967 to 1967...\n",
      "ERA5 data (1967-1967) loaded successfully.\n",
      "Loading ERA5 data from 1968 to 1968...\n",
      "ERA5 data (1968-1968) loaded successfully.\n",
      "Loading ERA5 data from 1969 to 1969...\n",
      "ERA5 data (1969-1969) loaded successfully.\n",
      "Loading ERA5 data from 1970 to 1970...\n",
      "ERA5 data (1970-1970) loaded successfully.\n",
      "Loading ERA5 data from 1971 to 1971...\n",
      "ERA5 data (1971-1971) loaded successfully.\n",
      "Loading ERA5 data from 1972 to 1972...\n",
      "ERA5 data (1972-1972) loaded successfully.\n",
      "Loading ERA5 data from 1973 to 1973...\n",
      "ERA5 data (1973-1973) loaded successfully.\n",
      "Loading ERA5 data from 1974 to 1974...\n",
      "ERA5 data (1974-1974) loaded successfully.\n",
      "Loading ERA5 data from 1975 to 1975...\n",
      "ERA5 data (1975-1975) loaded successfully.\n",
      "Loading ERA5 data from 1976 to 1976...\n",
      "ERA5 data (1976-1976) loaded successfully.\n",
      "Loading ERA5 data from 1977 to 1977...\n",
      "ERA5 data (1977-1977) loaded successfully.\n",
      "Loading ERA5 data from 1978 to 1978...\n",
      "ERA5 data (1978-1978) loaded successfully.\n",
      "Loading ERA5 data from 1979 to 1979...\n",
      "ERA5 data (1979-1979) loaded successfully.\n",
      "Loading ERA5 data from 1980 to 1980...\n",
      "ERA5 data (1980-1980) loaded successfully.\n",
      "Loading ERA5 data from 1981 to 1981...\n",
      "ERA5 data (1981-1981) loaded successfully.\n",
      "Loading ERA5 data from 1982 to 1982...\n",
      "ERA5 data (1982-1982) loaded successfully.\n",
      "Loading ERA5 data from 1983 to 1983...\n",
      "ERA5 data (1983-1983) loaded successfully.\n",
      "Loading ERA5 data from 1984 to 1984...\n",
      "ERA5 data (1984-1984) loaded successfully.\n",
      "Loading ERA5 data from 1985 to 1985...\n",
      "ERA5 data (1985-1985) loaded successfully.\n",
      "Loading ERA5 data from 1986 to 1986...\n",
      "ERA5 data (1986-1986) loaded successfully.\n",
      "Loading ERA5 data from 1987 to 1987...\n",
      "ERA5 data (1987-1987) loaded successfully.\n",
      "Loading ERA5 data from 1988 to 1988...\n",
      "ERA5 data (1988-1988) loaded successfully.\n",
      "Loading ERA5 data from 1989 to 1989...\n",
      "ERA5 data (1989-1989) loaded successfully.\n",
      "Loading ERA5 data from 1990 to 1990...\n",
      "ERA5 data (1990-1990) loaded successfully.\n",
      "Loading ERA5 data from 1991 to 1991...\n",
      "ERA5 data (1991-1991) loaded successfully.\n",
      "Loading ERA5 data from 1992 to 1992...\n",
      "ERA5 data (1992-1992) loaded successfully.\n",
      "Loading ERA5 data from 1993 to 1993...\n",
      "ERA5 data (1993-1993) loaded successfully.\n",
      "Loading ERA5 data from 1994 to 1994...\n",
      "ERA5 data (1994-1994) loaded successfully.\n",
      "Loading ERA5 data from 1995 to 1995...\n",
      "ERA5 data (1995-1995) loaded successfully.\n",
      "Loading ERA5 data from 1996 to 1996...\n",
      "ERA5 data (1996-1996) loaded successfully.\n",
      "Loading ERA5 data from 1997 to 1997...\n",
      "ERA5 data (1997-1997) loaded successfully.\n",
      "Loading ERA5 data from 1998 to 1998...\n",
      "ERA5 data (1998-1998) loaded successfully.\n",
      "Loading ERA5 data from 1999 to 1999...\n",
      "ERA5 data (1999-1999) loaded successfully.\n",
      "Loading ERA5 data from 2000 to 2000...\n",
      "ERA5 data (2000-2000) loaded successfully.\n",
      "Loading ERA5 data from 2001 to 2001...\n",
      "ERA5 data (2001-2001) loaded successfully.\n",
      "Loading ERA5 data from 2002 to 2002...\n",
      "ERA5 data (2002-2002) loaded successfully.\n",
      "Loading ERA5 data from 2003 to 2003...\n",
      "ERA5 data (2003-2003) loaded successfully.\n",
      "Loading ERA5 data from 2004 to 2004...\n",
      "ERA5 data (2004-2004) loaded successfully.\n",
      "Loading ERA5 data from 2005 to 2005...\n",
      "ERA5 data (2005-2005) loaded successfully.\n",
      "Loading ERA5 data from 2006 to 2006...\n",
      "ERA5 data (2006-2006) loaded successfully.\n",
      "Loading ERA5 data from 2007 to 2007...\n",
      "ERA5 data (2007-2007) loaded successfully.\n",
      "Loading ERA5 data from 2008 to 2008...\n",
      "ERA5 data (2008-2008) loaded successfully.\n",
      "Loading ERA5 data from 2009 to 2009...\n",
      "ERA5 data (2009-2009) loaded successfully.\n",
      "Loading ERA5 data from 2010 to 2010...\n",
      "ERA5 data (2010-2010) loaded successfully.\n",
      "Loading ERA5 data from 2011 to 2011...\n",
      "ERA5 data (2011-2011) loaded successfully.\n",
      "Loading ERA5 data from 2012 to 2012...\n",
      "ERA5 data (2012-2012) loaded successfully.\n",
      "Loading ERA5 data from 2013 to 2013...\n",
      "ERA5 data (2013-2013) loaded successfully.\n",
      "Loading ERA5 data from 2014 to 2014...\n",
      "ERA5 data (2014-2014) loaded successfully.\n",
      "Loading ERA5 data from 2015 to 2015...\n",
      "ERA5 data (2015-2015) loaded successfully.\n",
      "Loading ERA5 data from 2016 to 2016...\n",
      "ERA5 data (2016-2016) loaded successfully.\n",
      "Loading ERA5 data from 2017 to 2017...\n",
      "ERA5 data (2017-2017) loaded successfully.\n",
      "Loading ERA5 data from 2018 to 2018...\n",
      "ERA5 data (2018-2018) loaded successfully.\n",
      "Loading ERA5 data from 2019 to 2019...\n",
      "ERA5 data (2019-2019) loaded successfully.\n",
      "Loading ERA5 data from 2020 to 2020...\n",
      "ERA5 data (2020-2020) loaded successfully.\n",
      "Loading ERA5 data from 2021 to 2021...\n",
      "ERA5 data (2021-2021) loaded successfully.\n",
      "Loading ERA5 data from 2022 to 2022...\n",
      "ERA5 data (2022-2022) loaded successfully.\n",
      "Loading ERA5 data from 2023 to 2023...\n",
      "ERA5 data (2023-2023) loaded successfully.\n",
      "Loading ERA5 data from 2024 to 2024...\n",
      "ERA5 data (2024-2024) loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "if stations_to_process:\n",
    "    #batches = [(1940 + i*5, 1944 + i*5) for i in range(17)] \n",
    "    batches = np.tile(np.arange(1940,2025), (2,1)).T\n",
    "\n",
    "    for jj, (start_year, end_year) in enumerate(batches):\n",
    "        # Load only data in the batch range\n",
    "        w500_ds, vimd_ds = load_era5_data(start_year, end_year)\n",
    "\n",
    "        for idx, row in stations_to_process:\n",
    "            stn_id = row[\"StnID\"]\n",
    "            lon, lat = row[\"Lon\"], row[\"Lat\"]\n",
    "            utc_offset = pd.Timedelta(hours=row[\"UTC_Offset\"])\n",
    "\n",
    "            # Extract local hourly ERA5 → daily\n",
    "            era5_df = extract_era5_at_station(lat, lon, utc_offset, w500_ds, vimd_ds)\n",
    "\n",
    "            # Save partial result for merging later\n",
    "            era5_df.to_csv(temp_dir / f\"{stn_id}_temp_b{jj}.csv\")\n",
    "\n",
    "        w500_ds.close()\n",
    "        vimd_ds.close()\n",
    "\n",
    "else:\n",
    "    print(\"All stations already processed - nothing to do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final concatenation step\n",
    "if stations_to_process:\n",
    "    for idx, row in stations_to_process:\n",
    "        stn_id = row[\"StnID\"]\n",
    "        merged = []\n",
    "        for jj in range(len(batches)):\n",
    "            temp_file = temp_dir / f\"{stn_id}_temp_b{jj}.csv\"\n",
    "            merged.append(pd.read_csv(temp_file, index_col=0, parse_dates=True))\n",
    "        full_df = pd.concat(merged).sort_index()\n",
    "        full_df.to_csv(ERA5_PATH / f\"{stn_id}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ced484",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
